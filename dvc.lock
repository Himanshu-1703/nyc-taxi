schema: '2.0'
stages:
  extract_dataset:
    cmd: python .\src\data\extract_dataset.py
    deps:
    - path: .\data\raw\zipped
      hash: md5
      md5: 2ac9e57fc0bc2d2a1a610a695529d479.dir
      size: 87295035
      nfiles: 2
    - path: .\src\data\extract_dataset.py
      hash: md5
      md5: e13ce767752277added5382c0f74dfe9
      size: 1711
    outs:
    - path: .\data\raw\extracted
      hash: md5
      md5: 07dcb976ec534725901d50758a399273.dir
      size: 271383386
      nfiles: 2
  make_dataset:
    cmd: python .\src\data\make_dataset.py train.csv
    deps:
    - path: .\data\raw\extracted\train.csv
      hash: md5
      md5: e59c291a4b1c640f1dab33b89daa22e1
      size: 200589097
    - path: .\src\data\make_dataset.py
      hash: md5
      md5: 63f7cb7eb76659d9face16c29dc0e15b
      size: 4052
    params:
      params.yaml:
        make_dataset.random_state: 30
        make_dataset.test_size: 0.1
    outs:
    - path: .\data\interim
      hash: md5
      md5: 5441a97a8e44bdeb11d92d9f11b71186.dir
      size: 197004804
      nfiles: 2
